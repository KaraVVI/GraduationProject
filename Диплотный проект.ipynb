{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8iWTTZr9Jkb"
   },
   "source": [
    "## Импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuyHyOb-4bU5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import timit_utils as tu\n",
    "import timit_utils.audio_utils as au\n",
    "import timit_utils.drawing_utils as du\n",
    "#import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEUcRoEgAovJ"
   },
   "source": [
    "## Загрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "a_1CwZP9To7n",
    "outputId": "4f843133-0637-446a-bb20-eac0ae278c94"
   },
   "outputs": [],
   "source": [
    "device_num = 0\n",
    "device = f\"cuda:{device_num}\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_properties(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8vA6FCqMB5N"
   },
   "outputs": [],
   "source": [
    "# сохраняем путь к папке\n",
    "_TIMIT_PATH = 'data/lisa/data/timit/raw/TIMIT'\n",
    "# in speech processing, the recommended value is 512, corresponding to 23 milliseconds at a sample rate of 22050 Hz\n",
    "# для 16000 Hz n_fft = 372\n",
    "n_fft = 512#32ms\n",
    "sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HFeXSb5sYzjw",
    "outputId": "5f5a2798-eaa2-4ef3-bc40-823551baa0f4"
   },
   "outputs": [],
   "source": [
    "# прослушаем пример аудизаписи\n",
    "data, sr = librosa.load('data/lisa/data/timit/raw/TIMIT/TRAIN/DR1/MCPM0/SA2.WAV', sr=sr, mono=True)\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "WuArHRKaXugK",
    "outputId": "280900dd-576d-4c96-a31f-cf458cb99535"
   },
   "outputs": [],
   "source": [
    "IPython.display.Audio(data, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "1k2f_HdYaPoh",
    "outputId": "422d600e-4ff8-474e-995a-541daa3387ee"
   },
   "outputs": [],
   "source": [
    "# посмотрим на график\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(data)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58KPDDULp8O8"
   },
   "source": [
    "## Ручная проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gRNuDLPqqYQ"
   },
   "source": [
    "#### Преобразование Фурье и Mel-спектрограмма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKm1W_CLgXVm",
    "outputId": "6fa98411-3096-4d9a-a346-00ed28f539c7"
   },
   "outputs": [],
   "source": [
    "# выполним оконное преобразование Фурье\n",
    "data_stft = librosa.stft(y=data, n_fft=n_fft, window='blackman', hop_length=n_fft//4)\n",
    "# построим спектрограмму\n",
    "data_stft = np.abs(data_stft)\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(data_stft, ref=np.max),x_axis='s', y_axis='log', sr=sr, ax=ax)\n",
    "ax.set_title('Power spectrogram')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "data_stft.shape, type(data_stft[0][0]), data_stft[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X52LLu15Kfyo",
    "outputId": "16241e09-4d75-49b6-b9cb-c46a7237e8ea"
   },
   "outputs": [],
   "source": [
    "# mel-спектрограмма\n",
    "D = np.abs(librosa.stft(data))**2\n",
    "S = librosa.feature.melspectrogram(S=D, sr=sr, n_fft=n_fft)\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "img = librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sr, ax=ax)\n",
    "ax.set_title('Mel-frequency spectrogram')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnjRki1wrGE_"
   },
   "source": [
    "#### Работа с корпусом TIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLqzqAiW-3IK",
    "outputId": "9c939d3b-a676-4ece-fb0a-c004093f478a"
   },
   "outputs": [],
   "source": [
    "# считаем корпус TITIM через Timit-utils\n",
    "corpus = tu.Corpus(_TIMIT_PATH)\n",
    "# прочитаем первого человека в первой папке\n",
    "p = corpus.train.region_by_index(0).person_by_index(0)\n",
    "p.name, p.gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4PNXl_ODYL2",
    "outputId": "0ccd3fd7-e144-4a0d-f00b-747b4b038311"
   },
   "outputs": [],
   "source": [
    "# каждым человеком записано несколько дорожек\n",
    "len(corpus.train.region_by_index(0).person_by_index(0).sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDav9T5YDPN0",
    "outputId": "cfcf5000-726e-42d4-8ae3-afc6e3885f98"
   },
   "outputs": [],
   "source": [
    "# список имен\n",
    "corpus.train.people_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odzD_NurOK1R",
    "outputId": "eadc68bf-0409-41f8-c76f-c91710c13aa8"
   },
   "outputs": [],
   "source": [
    "# посморим список фраз, которые есть\n",
    "p.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gx6entyzO6xg"
   },
   "outputs": [],
   "source": [
    "# считаем первую дорожку\n",
    "data = p.sentence_by_index(0).raw_audio \n",
    "sr = p.sentence_by_index(0).sample_rate\n",
    "words = p.sentence_by_index(0).words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nHsxe-3q4Eqi",
    "outputId": "1b14e0d3-a454-4b08-cb5d-2b0316847a67"
   },
   "outputs": [],
   "source": [
    "# пример визуализации через TIMIT-UTILS с GitHub\n",
    "gained_padded_audio = au.audio_gained(au.audio_zero_padded(512, data, 8000), 1.0)\n",
    "audio_features = au.audio_features(gained_padded_audio, sr)\n",
    "sampled_audio = au.resampled_audio(data, sample_rate = sr, pad = 8000, to_sample_rate = 16000)\n",
    "print(gained_padded_audio.shape, sampled_audio.shape, audio_features.shape)\n",
    "du.DrawVerticalPanels([du.AudioPanel(data, show_x_axis=True), \n",
    "                       du.WordsPanel(words, data.shape[0], show_x_axis=True),\n",
    "                       #du.PhonesPanel(s0.phones_df, s0.raw_audio.shape[0]),\n",
    "                       #du.AudioPanel(sampled_audio, show_x_axis=True),\n",
    "                       ##du.WordsPanel(sentence_words_input, sampled_audio.shape[0], show_x_axis=True),\n",
    "                       ##du.PhonesPanel(sentence_phones_input, sampled_audio.shape[0]),\n",
    "                       #du.SignalsPanel(audio_features)\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUCrwOpwcmzs"
   },
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jN4dZPiYqOM0"
   },
   "source": [
    "#### Объявление функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRywQe322fqh"
   },
   "outputs": [],
   "source": [
    "# объявим функцию, которая будет принимать дорожку, делать STFT, mel и строить график по запросу\n",
    "def get_mel(data, sr=16000, n_fft=1024, sec=2.04, draw=False, fill_zero=False):\n",
    "\n",
    "    # если короче 3 секунд - добиваем нулями\n",
    "    if data.shape[0] < int(sr*sec):\n",
    "      if fill_zero:\n",
    "        data = np.concatenate((data, np.zeros(int(sr*sec)-data.shape[0])), axis=0)\n",
    "      else:\n",
    "        data = np.pad(data,data.shape[0], 'reflect')\n",
    "    # берем первые 3 секунды\n",
    "    D = np.abs(librosa.stft(data[:int(sr*sec)], n_fft = n_fft,hop_length=n_fft//4))**2\n",
    "    S = librosa.feature.melspectrogram(S=D, sr=sr, n_fft=n_fft,hop_length=n_fft//4)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    if draw == True:\n",
    "      fig, ax = plt.subplots(figsize=(20,5))\n",
    "      img = librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sr, ax=ax)\n",
    "      ax.set_title('Mel-frequency spectrogram')\n",
    "      fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "\n",
    "    return S_dB#.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "AzdjTbXcPkHL",
    "outputId": "19b20528-f6d8-4b7c-9ef9-993057f528b1"
   },
   "outputs": [],
   "source": [
    "# проверка работы функции\n",
    "S2 = get_mel(data, sr=sr, n_fft=1024,sec=2.04, draw=True)\n",
    "type(S2), S2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "255K42sZk6_b"
   },
   "outputs": [],
   "source": [
    "# объявим функцию нормализации спектрограммы\n",
    "def mel_norm(S_dB):\n",
    "\n",
    "  mean = S_dB.mean()\n",
    "  std = S_dB.std()\n",
    "  S_dB_norm = (S_dB - mean)/(std + 0.000001)\n",
    "  S_dB_min = S_dB_norm.min()\n",
    "  S_dB_max = S_dB_norm.max()\n",
    "  S_dB_scaled = (S_dB_norm - S_dB_min)/(S_dB_max - S_dB_min)#255*\n",
    "\n",
    "  return S_dB_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SPKRinfo.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "VSNoAO7nyC7N",
    "outputId": "5d81fd3f-904c-4a90-fd13-cfe8dd98eba9"
   },
   "outputs": [],
   "source": [
    "# в dataset хранятся имя, пол, возраст и другие дополнительные фичи\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylHaSX3hdR5O",
    "outputId": "bdb723dd-1afd-435e-d58a-053a8ce67e57"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qxe7-clTC66",
    "outputId": "8930127a-5b43-4a3e-cc78-3da41f8992d8"
   },
   "outputs": [],
   "source": [
    "df['age'].mean(), df['age'].min(), df['age'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "nUsRgjZGmw5a",
    "outputId": "9e719c80-13fd-4873-cf55-6d83a63f03d8"
   },
   "outputs": [],
   "source": [
    "# посмотрим на рапсределение возраста в train и test\n",
    "df[df['Use']=='TRN']['age'].plot.hist(bins=20),df[df['Use']=='TST']['age'].plot.hist(bins=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acla_U1U8Ktw"
   },
   "outputs": [],
   "source": [
    "# определим функцию которая считает количество записей из корпуса TIMIT\n",
    "# для train или test \n",
    "\n",
    "def count_TIMIT_sent(corpus_path, subcorp='train'):\n",
    "\n",
    "  persons_name = []\n",
    "  persons_gender = []\n",
    "  count = 0\n",
    "  count_pers = 0\n",
    "  corpus = tu.Corpus(corpus_path)\n",
    "  \n",
    "  if subcorp == 'train':\n",
    "    temp_subregion = corpus.train\n",
    "  elif subcorp == 'test':\n",
    "    temp_subregion = corpus.test\n",
    "\n",
    "  i = 0\n",
    "  n_regions = len(temp_subregion.regions)\n",
    "  while i < n_regions:\n",
    "    j = 0\n",
    "    n_persons = len(temp_subregion.region_by_index(i).people)\n",
    "    while j < n_persons:\n",
    "      count = count + len(temp_subregion.region_by_index(i).person_by_index(j).sentences)\n",
    "      j = j + 1\n",
    "    i = i + 1  \n",
    "\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFnrz6FiykVi",
    "outputId": "01a3dc40-60b7-43bd-a89c-712e52ef7b40"
   },
   "outputs": [],
   "source": [
    "# посмортим кол-во записей в train и test\n",
    "train_sent_count = count_TIMIT_sent(_TIMIT_PATH)\n",
    "test_sent_count = count_TIMIT_sent(_TIMIT_PATH, subcorp='test')\n",
    "train_sent_count, test_sent_count, test_sent_count/(train_sent_count + test_sent_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YgRn5z-orSxe",
    "outputId": "769418b7-50d1-4139-95b1-6d98edd3d379"
   },
   "outputs": [],
   "source": [
    "df[df['Use']=='TRN'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-b5_Oz7Wos9"
   },
   "outputs": [],
   "source": [
    "# напишем фунцию, которая берет ID из датасета, ищет в корпусе TIMIT\n",
    "# дорожки, преобразует их в mel-спектрограмму и складывет их в один массив,\n",
    "# а пол и возраст в другой\n",
    "def mel_TIMIT(corpus_path, dataset, subcorp='train', sr=16000, n_fft=1024, sec=2.04):\n",
    "\n",
    "  corpus = tu.Corpus(corpus_path)\n",
    "  # определяем где искать\n",
    "  if subcorp == 'train':\n",
    "    filter = \"TRN\"\n",
    "  else:\n",
    "    filter = \"TST\"\n",
    "  # объявляем переменные\n",
    "  dataset = dataset[dataset['Use'] == filter]\n",
    "  mel_set = np.zeros([dataset.shape[0]*10,int(n_fft/8),128]) #int(n_fft/4)  int((sr*sec-n_fft/4)/n_fft+1)\n",
    "  gender_set = np.zeros(dataset.shape[0]*10)\n",
    "  age_set = np.zeros(dataset.shape[0]*10)\n",
    "  age_class = np.zeros(dataset.shape[0]*10)\n",
    "  x = 0\n",
    "  # перебираем ID\n",
    "  for id in tqdm(dataset['ID']):\n",
    "    # определяем где искать\n",
    "    if subcorp == 'train':\n",
    "      person = corpus.train.person_by_name(id)\n",
    "    else:\n",
    "      person = corpus.test.person_by_name(id)\n",
    "    # для каждого ID определяем пол и возраст\n",
    "    gender = person.gender\n",
    "    age = dataset[dataset['ID']==id]['age']\n",
    "    age_cls = dataset[dataset['ID']==id]['AgeClass']\n",
    "    # кодируем пол в [0,1]\n",
    "    if gender == \"M\":\n",
    "      gender = 0\n",
    "    else:\n",
    "      gender = 1\n",
    "    n_sentences = len(person.sentences)\n",
    "    # перебираем все sentences для данного ID\n",
    "    for sent in person.sentences:\n",
    "      sentence = person.sentence_by_name(sent)\n",
    "      mel_set[x] = mel_norm(get_mel(sentence.raw_audio,sr=sr,n_fft=n_fft, sec = sec))\n",
    "      gender_set[x] = gender\n",
    "      age_set[x] = age\n",
    "      age_class[x] = age_cls\n",
    "      x = x + 1\n",
    "  \n",
    "  return mel_set, gender_set, age_set, age_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dN0bFm3rDmS"
   },
   "source": [
    "#### Преобразование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cT5RkkcKYyGq",
    "outputId": "46f418a1-559e-4b82-a281-c6f267bd1d38"
   },
   "outputs": [],
   "source": [
    "X_train, y_train1, y_train2, y_train3 = mel_TIMIT(_TIMIT_PATH, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_VqQghDqcmk",
    "outputId": "ffb13060-cbce-41a9-8055-fca1b22f5530"
   },
   "outputs": [],
   "source": [
    "# изменим размернсоти для подачи в нейросеть\n",
    "X_train1 = np.expand_dims(X_train, axis=1)\n",
    "y_train1 = np.expand_dims(y_train1, axis=1)\n",
    "y_train2 = np.expand_dims(y_train2, axis=1)\n",
    "y_train3 = np.expand_dims(y_train3, axis=1)\n",
    "y_train1.shape, y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "WwBPQqRwPf97",
    "outputId": "3bda9bd0-75b8-46b6-9456-78e486b7eb6e"
   },
   "outputs": [],
   "source": [
    "#убедимся что преобразование произошло корректно\n",
    "ig, ax = plt.subplots(figsize=(20,5))\n",
    "import seaborn as sns\n",
    "# img =np.reshape( X_train[0],(128,94))\n",
    "sns.heatmap(X_train[10])\n",
    "ax.invert_yaxis()\n",
    "X_train[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sD_0ye92fHq0",
    "outputId": "ff7f6fb4-84c3-4187-9371-4b676fbe8e72"
   },
   "outputs": [],
   "source": [
    "X_test, y_test1, y_test2, y_test3 = mel_TIMIT(_TIMIT_PATH, df, subcorp='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cReg_uRwp3-8"
   },
   "outputs": [],
   "source": [
    "X_test1=np.expand_dims(X_test, axis=1)\n",
    "y_test1=np.expand_dims(y_test1, axis=1)\n",
    "y_test2=np.expand_dims(y_test2, axis=1)\n",
    "y_test3=np.expand_dims(y_test3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wk3ul4x9CAc",
    "outputId": "58ee4e4d-8367-4305-fefb-56efeacbe00a"
   },
   "outputs": [],
   "source": [
    "X_train1.shape, X_test1.shape, y_train1.shape, y_test1.shape,y_train3.shape, y_test3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP6e0D7rExnk"
   },
   "source": [
    "## Работа с нейросетью (определение пола)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1faFUHzQbS_K"
   },
   "source": [
    "#### Создание тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L78fweXmVB9S"
   },
   "outputs": [],
   "source": [
    "# опишем класс, который будет преобразовывать исходный массив в тензор\n",
    "class PeopleDataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, X, y, target = False):\n",
    "   \n",
    "    self.x_data = torch.tensor(X, dtype = torch.float32)#.to(device)\n",
    "    if target == False:\n",
    "      self.y_data = torch.tensor(y, dtype = torch.float32)#.to(device)\n",
    "    else:\n",
    "      self.y_data = torch.tensor(y, dtype = torch.long)\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)  # required\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    if torch.is_tensor(idx):\n",
    "      idx = idx.tolist()\n",
    "    spec = self.x_data[idx]\n",
    "    tar = self.y_data[idx]\n",
    "\n",
    "    sample = (spec,tar)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_39MkvMmaL5q"
   },
   "outputs": [],
   "source": [
    "train_dataset = PeopleDataset(X_train1,y_train1)\n",
    "test_dataset = PeopleDataset(X_test1,y_test1)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [3696, 924],generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRyfp-EP6mMR",
    "outputId": "bce828aa-682f-4c25-f3bc-15955efa5344"
   },
   "outputs": [],
   "source": [
    "# проверим результат\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdkP26Z5x1_B"
   },
   "source": [
    "#### Генератор батчей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0FjPPlvkCtb"
   },
   "outputs": [],
   "source": [
    "# Инициализируем генераторы батчей\n",
    "batch_size = 32\n",
    "\n",
    "train_batch_gen = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_batch_gen = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_batch_gen = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "718v-B8aB-6T",
    "outputId": "40e1a467-0c81-4791-8b0f-661c2012d479"
   },
   "outputs": [],
   "source": [
    "print(len(train_batch_gen))\n",
    "train_features, train_labels = next(iter(train_batch_gen))\n",
    "print(f\"Feature batch shape: {train_features.size()[0]}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGsXe3uTskO5"
   },
   "source": [
    "#### Объявление функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-stuYTNjR2rc"
   },
   "outputs": [],
   "source": [
    "# Функция для обучения нейросети\n",
    "\n",
    "def train(model,criterion,optimizer,train_batch_gen,val_batch_gen,num_epochs=50):\n",
    "    '''\n",
    "    Функция для обучения модели и вывода лосса и метрики во время обучения.\n",
    "    :param model: обучаемая модель\n",
    "    :param criterion: функция потерь\n",
    "    :param optimizer: метод оптимизации\n",
    "    :param train_batch_gen: генератор батчей для обучения\n",
    "    :param val_batch_gen: генератор батчей для валидации\n",
    "    :param num_epochs: количество эпох\n",
    "    :return: обученная модель\n",
    "    :return: (dict) accuracy и loss на обучении и валидации (\"история\" обучения)\n",
    "    '''\n",
    "\n",
    "\n",
    "    history = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_prec = 0\n",
    "        train_rec = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        val_prec = 0\n",
    "        val_rec = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Устанавливаем поведение dropout / batch_norm  в обучение\n",
    "        model.train(True) \n",
    "\n",
    "        # На каждой \"эпохе\" делаем полный проход по данным\n",
    "        for X_batch,y_batch in train_batch_gen:\n",
    "            # Обучаемся на батче (одна \"итерация\" обучения нейросети)\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch.float().to(device))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_loss += np.sum(loss.detach().cpu().numpy())\n",
    "            y_pred = logits.round().detach().cpu().numpy()\n",
    "            train_acc += np.mean(y_batch.cpu().numpy() == y_pred)\n",
    "            #prec=TP/(TP+FP)\n",
    "            TP = np.sum(y_batch.cpu().numpy())\n",
    "            if np.sum(y_pred) > TP:\n",
    "              FP = np.sum(y_pred) - TP\n",
    "            else:\n",
    "              FP = 0\n",
    "            train_prec += TP/(TP+FP+0.000001)\n",
    "            #rec=TP/(TP+FN)\n",
    "            F_target = X_batch.size()[0] - np.sum(y_batch.cpu().numpy())\n",
    "            F_pred = X_batch.size()[0] - np.sum(y_pred)\n",
    "            if F_pred > F_target:\n",
    "              FN = F_pred - F_target\n",
    "            else:\n",
    "              FN = 0        \n",
    "            train_rec += TP/(TP+FN+0.000001)\n",
    "\n",
    "        # Подсчитываем лоссы и сохраням в \"историю\"\n",
    "        train_loss /= len(train_batch_gen)\n",
    "        train_acc /= len(train_batch_gen) \n",
    "        train_prec /= len(train_batch_gen)\n",
    "        train_rec /= len(train_batch_gen)\n",
    "        history['loss']['train'].append(train_loss)\n",
    "        history['acc']['train'].append(train_acc)\n",
    "        history['prec']['train'].append(train_prec)\n",
    "        history['rec']['train'].append(train_rec)\n",
    "\n",
    "        # Устанавливаем поведение dropout / batch_norm в режим тестирования\n",
    "        model.train(False)\n",
    "\n",
    "        # Полный проход по валидации    \n",
    "        for X_batch, y_batch in val_batch_gen:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                logits = model(X_batch)\n",
    "                \n",
    "                loss = criterion(logits, y_batch.float().to(device))\n",
    "                val_loss += np.sum(loss.detach().cpu().numpy())\n",
    "                y_pred = logits.round().detach().cpu().numpy()#max(1)[1]\n",
    "                val_acc += np.mean(y_batch.cpu().numpy() == y_pred)\n",
    "                #prec=TP/(TP+FP)\n",
    "                TP = np.sum(y_batch.cpu().numpy())\n",
    "                if np.sum(y_pred) > TP:\n",
    "                  FP = np.sum(y_pred) - TP\n",
    "                else:\n",
    "                  FP = 0\n",
    "                val_prec += TP/(TP+FP+0.000001)\n",
    "                #rec=TP/(TP+FN)\n",
    "                F_target = X_batch.size()[0] - np.sum(y_batch.cpu().numpy())\n",
    "                F_pred = X_batch.size()[0] - np.sum(y_pred)\n",
    "                if F_pred > F_target:\n",
    "                  FN = F_pred - F_target\n",
    "                else:\n",
    "                  FN = 0        \n",
    "                val_rec += TP/(TP+FN+0.000001)\n",
    "\n",
    "        # Подсчитываем лоссы и сохраням в \"историю\"\n",
    "        val_loss /= len(val_batch_gen)\n",
    "        val_acc /= len(val_batch_gen) \n",
    "        val_prec /= len(val_batch_gen)\n",
    "        val_rec /= len(val_batch_gen)\n",
    "        history['loss']['val'].append(val_loss)\n",
    "        history['acc']['val'].append(val_acc)\n",
    "        history['prec']['val'].append(val_prec)\n",
    "        history['rec']['val'].append(val_rec)\n",
    "        \n",
    "        IPython.display.clear_output()\n",
    "\n",
    "        # Печатаем результаты после каждой эпохи\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(train_loss))\n",
    "        print(\"  validation loss (in-iteration): \\t{:.6f}\".format(val_loss))  \n",
    "        print(\"  training accuracy: \\t\\t\\t{:.2f} %\".format(train_acc * 100))\n",
    "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(val_acc * 100))\n",
    "        print(\"  training precision: \\t\\t\\t{:.2f} %\".format(train_prec*100))\n",
    "        print(\"  validation precision: \\t\\t{:.2f} %\".format(val_prec*100))\n",
    "        print(\"  training recall: \\t\\t\\t{:.2f} %\".format(train_rec*100))\n",
    "        print(\"  validation recall: \\t\\t\\t{:.2f} %\".format(val_rec*100))\n",
    "         \n",
    "    plot_learning_curves(history)\n",
    "        \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rj72rtmi-zbd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    '''\n",
    "    Функция для обучения модели и вывода лосса и метрики во время обучения.\n",
    "\n",
    "    :param history: (dict)\n",
    "        accuracy и loss на обучении и валидации\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.title('Loss', fontsize=15)\n",
    "    plt.plot(history['loss']['train'], label='train')\n",
    "    plt.plot(history['loss']['val'], label='val')\n",
    "    plt.ylabel('loss', fontsize=15)\n",
    "    plt.xlabel('epoch', fontsize=15)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.title('Accuracy', fontsize=15)\n",
    "    plt.plot(history['acc']['train'], label='train')\n",
    "    plt.plot(history['acc']['val'], label='val')\n",
    "    plt.ylabel('acc', fontsize=15)\n",
    "    plt.xlabel('epoch', fontsize=15)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.title('Precision', fontsize=15)\n",
    "    plt.plot(history['prec']['train'], label='train')\n",
    "    plt.plot(history['prec']['val'], label='val')\n",
    "    plt.ylabel('prec', fontsize=15)\n",
    "    plt.xlabel('epoch', fontsize=15)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2,2,4)\n",
    "    plt.title('Recall', fontsize=15)\n",
    "    plt.plot(history['rec']['train'], label='train')\n",
    "    plt.plot(history['rec']['val'], label='val')\n",
    "    plt.ylabel('rec', fontsize=15)\n",
    "    plt.xlabel('epoch', fontsize=15)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcmTIYMyhMuU"
   },
   "source": [
    "#### Объявление нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_RF1ZMXUJ2b"
   },
   "outputs": [],
   "source": [
    "#\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,num_classes=1,dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c1 = torch.nn.Conv2d(in_channels=1, out_channels=2048, kernel_size=[3,128], stride=(1,1), padding=(1,0))\n",
    "        self.bn1 = nn.BatchNorm2d(2048)\n",
    "        self.maxpool1 = nn.MaxPool1d(128)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.c2 = torch.nn.Conv2d(in_channels=1, out_channels=2048, kernel_size=[5,128], stride=(1,1), padding=(2,0))       \n",
    "        self.bn2 = nn.BatchNorm2d(2048)\n",
    "        self.maxpool2 = nn.MaxPool1d(128)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.c3 = torch.nn.Conv2d(in_channels=1, out_channels=2048, kernel_size=[7,128], stride=(1,1), padding=(3,0))   \n",
    "        self.bn3 = nn.BatchNorm2d(2048)\n",
    "        self.maxpool3 = nn.MaxPool1d(128)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.flt = torch.nn.Flatten()\n",
    "        self.fc1 = nn.Linear(6144,2048,bias=False)\n",
    "        self.bn4 = nn.BatchNorm1d(2048)\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc2 = nn.Linear(2048,2048,bias=False)\n",
    "        self.bn5 = nn.BatchNorm1d(2048)\n",
    "        self.dropout5 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc_out1 = nn.Linear(2048,num_classes)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x=torch.unsqueeze(x,1)\n",
    "        \n",
    "        x1=self.c1(x)\n",
    "        \n",
    "        x1=self.bn1(x1)\n",
    "        x1=torch.squeeze(x1,-1)\n",
    "        \n",
    "        x1=self.maxpool1(x1)\n",
    "        # x1 = F.max_pool1d(x1,x1.size(2))\n",
    "        \n",
    "        x1=self.act(x1)\n",
    "        x1=self.dropout1(x1)\n",
    "\n",
    "        # x=torch.unsqueeze(x,1)\n",
    "        \n",
    "        x2=self.c2(x)\n",
    "        \n",
    "        x2=self.bn2(x2)\n",
    "        x2=torch.squeeze(x2,-1)\n",
    "        \n",
    "        x2=self.maxpool2(x2)\n",
    "        # x2 = F.max_pool1d(x2,x2.size(2))\n",
    "        \n",
    "        x2=self.act(x2)\n",
    "        x2=self.dropout2(x2)\n",
    "\n",
    "        \n",
    "        x3=self.c3(x)\n",
    "        \n",
    "        x3=self.bn3(x3)\n",
    "        x3=torch.squeeze(x3,-1)\n",
    "       \n",
    "        x3=self.maxpool3(x3)\n",
    "        # x3 = F.max_pool1d(x3,x3.size(2))\n",
    "       \n",
    "        x3=self.act(x3)\n",
    "        x3=self.dropout2(x3)\n",
    "\n",
    "        x = torch.cat((x1,x2,x3),1)\n",
    "        x=self.flt(x)\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "\n",
    "        x= self.fc1(x)\n",
    "        x= self.bn4(x)\n",
    "        x= self.act(x)\n",
    "        x=self.dropout4(x)\n",
    "\n",
    "        x= self.fc2(x)\n",
    "        x= self.bn5(x)\n",
    "        x= self.act(x)\n",
    "        x=self.dropout5(x)\n",
    "        \n",
    "        x=self.fc_out1(x)\n",
    "       \n",
    "        # x = x.transpose(1, 0, 2, 3)\n",
    "        # x.view(x.size(0), -1)\n",
    "        # x = x.view(x.size(0),-1)\n",
    "        x = self.sigm(x)\n",
    "       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e21fM53hyxZs"
   },
   "source": [
    "#### Обучение нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHF_xbCMWx_d",
    "outputId": "8b3a51e6-2688-4be2-cda2-74bb8de0d79d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(num_classes=1).to(device)\n",
    "criterion = nn.BCELoss()#CrossEntropyLoss()#BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "# input to have size [batch_size, channels,  height, width]\n",
    "#                           32       1         128    128\n",
    "summary(model.to(device), ( 1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "id": "p16_Rre1yxLg",
    "outputId": "65ffd850-c81f-45ef-beb3-2d057df26774"
   },
   "outputs": [],
   "source": [
    "model, history = train(model, criterion, optimizer,train_batch_gen, val_batch_gen , num_epochs=5) #train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfADs1x0X89x"
   },
   "outputs": [],
   "source": [
    "# ручная проверка\n",
    "for X_batch,y_batch in train_batch_gen:\n",
    "            model.train(False)\n",
    "            # Обучаемся на батче (одна \"итерация\" обучения нейросети)\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)          \n",
    "            logits = model(X_batch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNFaCEeMYFNr",
    "outputId": "c6149538-c99a-4799-da4a-3aaccc56d2d3"
   },
   "outputs": [],
   "source": [
    "logits = logits.detach().cpu().numpy()\n",
    "y_batch = y_batch.detach().cpu().numpy()\n",
    "np.concatenate([y_batch,logits.round()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAkvRAM7Yn1u"
   },
   "outputs": [],
   "source": [
    "for X_batch,y_batch in val_batch_gen:\n",
    "            model.train(False)\n",
    "            # Обучаемся на батче (одна \"итерация\" обучения нейросети)\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)         \n",
    "            logits = model(X_batch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46feZQhxYs1y",
    "outputId": "bdd7d232-a7e6-41c0-97fe-73ad15852f80"
   },
   "outputs": [],
   "source": [
    "logits = logits.detach().cpu().numpy()\n",
    "y_batch = y_batch.detach().cpu().numpy()\n",
    "np.concatenate([y_batch,logits.round()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9TiOGhnE7Gz"
   },
   "source": [
    "## Работа с нейросетью (возраст)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmSJpZW2FM7I"
   },
   "source": [
    "#### Создание тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cioak9rpFdys"
   },
   "outputs": [],
   "source": [
    "train_dataset2 = PeopleDataset(X_train1,y_train2,True)\n",
    "test_dataset2 = PeopleDataset(X_test1,y_test2,True)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# train_dataset2, val_dataset2 = torch.utils.data.random_split(train_dataset2, [3696, 924],generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpsXSfI6FRq0"
   },
   "source": [
    "#### Генератор батчей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpC16vbxF2sF"
   },
   "outputs": [],
   "source": [
    "# Инициализируем генераторы батчей\n",
    "batch_size = 32\n",
    "\n",
    "train_batch_gen2 = torch.utils.data.DataLoader(train_dataset2, batch_size=batch_size, shuffle=True)\n",
    "val_batch_gen2 = torch.utils.data.DataLoader(test_dataset2, batch_size=batch_size, shuffle=True)\n",
    "# test_batch_gen2 = torch.utils.data.DataLoader(test_dataset2, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUUvsw09FX6E"
   },
   "source": [
    "#### Объявление функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnurF6e6FCLa"
   },
   "outputs": [],
   "source": [
    "def train2(model,criterion,optimizer,train_batch_gen,val_batch_gen,num_epochs=50):\n",
    "    '''\n",
    "    Функция для обучения модели и вывода лосса и метрики во время обучения.\n",
    "    :param model: обучаемая модель\n",
    "    :param criterion: функция потерь\n",
    "    :param optimizer: метод оптимизации\n",
    "    :param train_batch_gen: генератор батчей для обучения\n",
    "    :param val_batch_gen: генератор батчей для валидации\n",
    "    :param num_epochs: количество эпох\n",
    "    :return: обученная модель\n",
    "    :return: (dict) accuracy и loss на обучении и валидации (\"история\" обучения)\n",
    "    '''\n",
    "\n",
    "\n",
    "    history = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        train_MAE = 0\n",
    "        train_prec = 0\n",
    "        train_rec = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        val_MAE = 0\n",
    "        val_prec = 0\n",
    "        val_rec = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Устанавливаем поведение dropout / batch_norm  в обучение\n",
    "        model.train(True) \n",
    "\n",
    "        # На каждой \"эпохе\" делаем полный проход по данным\n",
    "        for X_batch,y_batch in train_batch_gen:\n",
    "            # Обучаемся на батче (одна \"итерация\" обучения нейросети)\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            logits = model(X_batch)\n",
    "           \n",
    "            loss = criterion(logits, y_batch.float().to(device))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_loss += np.sum(loss.detach().cpu().numpy())\n",
    "            #y_pred = logits.max(1)[1].detach().cpu().numpy()\n",
    "            y_pred = logits.round().detach().cpu().numpy()\n",
    "            y_true = y_batch.detach().cpu().numpy()\n",
    "            #train_acc += np.mean(y_batch.cpu().numpy() == y_pred)\n",
    "            train_MAE += np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "        # Подсчитываем лоссы и сохраням в \"историю\"\n",
    "        train_loss /= len(train_batch_gen)\n",
    "        #train_acc /= len(train_batch_gen)\n",
    "        train_MAE /= len(train_batch_gen) \n",
    "        history['loss']['train'].append(train_loss)\n",
    "        history['acc']['train'].append(train_MAE)\n",
    "        history['prec']['train'].append(train_prec)\n",
    "        history['rec']['train'].append(train_rec)\n",
    "        model.train(False)\n",
    "\n",
    "        # Полный проход по валидации    \n",
    "        for X_batch, y_batch in val_batch_gen:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                logits = model(X_batch)\n",
    "                \n",
    "                loss = criterion(logits, y_batch.float().to(device))\n",
    "                val_loss += np.sum(loss.detach().cpu().numpy())\n",
    "                #y_pred = logits.max(1)[1].detach().cpu().numpy()#max(1)[1]\n",
    "                y_pred = logits.round().detach().cpu().numpy()\n",
    "                y_true = y_batch.detach().cpu().numpy()\n",
    "                #val_acc += np.mean(y_batch.cpu().numpy() == y_pred)\n",
    "                val_MAE += np.mean(np.abs(y_true - y_pred))\n",
    "                \n",
    "        # Подсчитываем лоссы и сохраням в \"историю\"\n",
    "        val_loss /= len(val_batch_gen)\n",
    "        #val_acc /= len(val_batch_gen)\n",
    "        val_MAE /= len(val_batch_gen) \n",
    "        history['loss']['val'].append(val_loss)\n",
    "        history['acc']['val'].append(val_MAE)\n",
    "        history['prec']['val'].append(val_prec)\n",
    "        history['rec']['val'].append(val_rec)\n",
    "\n",
    "        IPython.display.clear_output()\n",
    "\n",
    "        # Печатаем результаты после каждой эпохи\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(train_loss))\n",
    "        print(\"  validation loss (in-iteration): \\t{:.6f}\".format(val_loss))  \n",
    "        print(\"  training MAE: \\t\\t\\t{:.2f}\".format(train_MAE))\n",
    "        print(\"  validation MAE: \\t\\t\\t{:.2f}\".format(val_MAE))\n",
    "         \n",
    "    plot_learning_curves(history)\n",
    "        \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3b8z1h3GVQz"
   },
   "source": [
    "#### Объявление нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODSmsO2NGa4O"
   },
   "outputs": [],
   "source": [
    "#\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self,num_classes=1,dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c1 = torch.nn.Conv2d(in_channels=1, out_channels=2048, kernel_size=[3,128], stride=(1,1), padding=(1,0))\n",
    "        self.bn1 = nn.BatchNorm2d(2048)\n",
    "        self.maxpool1 = nn.MaxPool1d(128)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.c2 = torch.nn.Conv2d(in_channels=1, out_channels=2048, kernel_size=[5,128], stride=(1,1), padding=(2,0))       \n",
    "        self.bn2 = nn.BatchNorm2d(2048)\n",
    "        self.maxpool2 = nn.MaxPool1d(128)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.c3 = torch.nn.Conv2d(in_channels=1, out_channels=2048, kernel_size=[7,128], stride=(1,1), padding=(3,0))   \n",
    "        self.bn3 = nn.BatchNorm2d(2048)\n",
    "        self.maxpool3 = nn.MaxPool1d(128)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.flt = torch.nn.Flatten()\n",
    "        self.fc1 = nn.Linear(16384,4096,bias=False)\n",
    "        self.bn4 = nn.BatchNorm1d(4096)\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc2 = nn.Linear(4096,2048,bias=False)\n",
    "        self.bn5 = nn.BatchNorm1d(2048)\n",
    "        self.dropout5 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc_out1 = nn.Linear(2048,num_classes)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x=torch.unsqueeze(x,1)\n",
    "        #print('1input    ',x.shape)\n",
    "        #x1=self.c1(x)\n",
    "        #print('1conv     ',x1.shape)\n",
    "        #x1=self.bn1(x1)\n",
    "        #x1=torch.squeeze(x1,-1)\n",
    "        #print('1squeeze  ',x1.shape)\n",
    "        #x1=self.maxpool1(x1)\n",
    "        # x1 = F.max_pool1d(x1,x1.size(2))\n",
    "        #print('1maxpool  ',x1.shape)\n",
    "        #x1=self.act(x1)\n",
    "        #x1=self.dropout1(x1)\n",
    "\n",
    "        # x=torch.unsqueeze(x,1)\n",
    "        #print('2input    ',x.shape)\n",
    "        #x2=self.c2(x)\n",
    "        #print('2conv     ',x2.shape)\n",
    "        #x2=self.bn2(x2)\n",
    "        #x2=torch.squeeze(x2,-1)\n",
    "        #print('2squeeze  ',x2.shape)\n",
    "        #x2=self.maxpool2(x2)\n",
    "        # x2 = F.max_pool1d(x2,x2.size(2))\n",
    "        #print('2maxpool  ',x2.shape)\n",
    "        #x2=self.act(x2)\n",
    "        #x2=self.dropout2(x2)\n",
    "\n",
    "        # print('3input    ',x.shape)\n",
    "        #x3=self.c3(x)\n",
    "        # print('3conv     ',x3.shape)\n",
    "        #x3=self.bn3(x3)\n",
    "        #x3=torch.squeeze(x3,-1)\n",
    "        # print('3squeeze  ',x3.shape)\n",
    "        #x3=self.maxpool3(x3)\n",
    "        # x3 = F.max_pool1d(x3,x3.size(2))\n",
    "        #print('3maxpool  ',x3.shape)\n",
    "        #x3=self.act(x3)\n",
    "        #x3=self.dropout2(x3)\n",
    "\n",
    "        #x = torch.cat((x1,x2,x3),1)\n",
    "        x=self.flt(x)\n",
    "        #print('flattern ',x.shape)\n",
    "        #x = x.view(x.size(0),-1)\n",
    "\n",
    "        x= self.fc1(x)\n",
    "        x= self.bn4(x)\n",
    "        x= self.act(x)\n",
    "        x=self.dropout4(x)\n",
    "\n",
    "        x= self.fc2(x)\n",
    "        x= self.bn5(x)\n",
    "        x= self.act(x)\n",
    "        x=self.dropout5(x)\n",
    "        #print('view     ',x.shape)\n",
    "        x=self.fc_out1(x)\n",
    "        #print('out      ',x.shape)\n",
    "        # x = x.transpose(1, 0, 2, 3)\n",
    "        # x.view(x.size(0), -1)\n",
    "        # x = x.view(x.size(0),-1)\n",
    "        #x = self.softmax(x)\n",
    "        # print('end       ',x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvwkoKtqG9OJ"
   },
   "source": [
    "#### Обучение нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yk_mMHvPHDB2",
    "outputId": "481f092c-cd66-465b-f0aa-bc55d1e2beb1"
   },
   "outputs": [],
   "source": [
    "model2 = Model2(num_classes=1).to(device)\n",
    "criterion2 = nn.MSELoss()#BCEWithLogitsLoss()CrossEntropyLoss()\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(),lr=0.001)\n",
    "# input to have size [batch_size, channels,  height, width]\n",
    "#                           32       1         128    128\n",
    "summary(model2.to(device), ( 1, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "id": "ce3fMxxVHiRU",
    "outputId": "cec174d2-f42e-42e1-c53e-1fff4ac7131f"
   },
   "outputs": [],
   "source": [
    "model2, history = train2(model2, criterion2, optimizer2, train_batch_gen2, val_batch_gen2 , num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VE1UuyOInRy"
   },
   "outputs": [],
   "source": [
    "for X_batch,y_batch in train_batch_gen2:\n",
    "            model2.train(False)\n",
    "            # Обучаемся на батче (одна \"итерация\" обучения нейросети)\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            logits = model2(X_batch)\n",
    "            y_pred = logits.max(1)[1]\n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eo9WgFQ-IuXe",
    "outputId": "d0b3fb65-0470-45e0-e81a-43b90cb526fa"
   },
   "outputs": [],
   "source": [
    "logits = logits.detach().cpu().numpy().reshape(12,1)\n",
    "y_batch = y_batch.detach().cpu().numpy().reshape(12,1)\n",
    "np.concatenate([y_batch,logits], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIolDIhsI9vf"
   },
   "outputs": [],
   "source": [
    "for X_batch,y_batch in val_batch_gen2:\n",
    "            # Обучаемся на батче (одна \"итерация\" обучения нейросети)\n",
    "            model.train(False)\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)         \n",
    "            logits = model2(X_batch)\n",
    "            y_pred = logits.max(1)[1]\n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8VhqcI_JEa9",
    "outputId": "b70919ff-ecca-41c8-c896-b47c74c1d53a"
   },
   "outputs": [],
   "source": [
    "logits = logits.detach().cpu().numpy().reshape(16,1)\n",
    "y_batch = y_batch.detach().cpu().numpy().reshape(16,1)\n",
    "np.concatenate([y_batch,logits], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA9KB_LekMMN"
   },
   "source": [
    "## Проверка на внешних данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkbTBCAYkeYN"
   },
   "source": [
    "#### Объявление функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQtv-TSwkj0W"
   },
   "outputs": [],
   "source": [
    "def get_mel_sample(data, model_sex, model_age, sr=16000, n_fft=1024, sec=2.04, fill_zero=False): \n",
    "\n",
    "  mel = mel_norm(get_mel(data,sr=sr,n_fft=n_fft, sec = sec))\n",
    "  mel = torch.tensor(mel, dtype = torch.float32).to(device)\n",
    "  mel = mel.unsqueeze(dim=0).unsqueeze(dim=0)\n",
    "  #mel = mel.unsqueeze(dim=0)\n",
    "  pred_sex = np.round(model_sex(mel)[0][0].detach().cpu().numpy())\n",
    "  pred_age = np.sum(model_age(mel)[0][0].detach().cpu().numpy())\n",
    "  if pred_sex == 0:\n",
    "    pred_sex = 'M'\n",
    "  else:\n",
    "    pred_sex = 'F'\n",
    "  return (pred_sex, pred_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHvmKbyYl8eH"
   },
   "outputs": [],
   "source": [
    "# проверка\n",
    "data, sr = librosa.load('/content/data/lisa/data/timit/raw/TIMIT/TRAIN/DR1/MCPM0/SA2.WAV', sr=sr, mono=True)\n",
    "S3 = get_mel_sample(data, model, model2)\n",
    "S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "VjW3ZJYIqASl",
    "outputId": "21942cd6-232e-4efa-8e4e-68bef411da8f"
   },
   "outputs": [],
   "source": [
    "df[df['SexID']=='MCPM0'][['Sex','age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hj9EUZo7ri69"
   },
   "outputs": [],
   "source": [
    "data, sr = librosa.load('/content/haters-low-pitched-male-vocal-fx_104bpm_G_minor (1).wav', sr=sr, mono=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKbw12WesxSH",
    "outputId": "6a6eabdd-2fc3-4418-cd29-9a7b13971059"
   },
   "outputs": [],
   "source": [
    "get_mel_sample(data, model, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6b6NGootSZl"
   },
   "outputs": [],
   "source": [
    "data, sr = librosa.load('/content/flowing-smooth-female-vocal-singing_113bpm.wav', sr=sr, mono=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZx3XlK8ugO5",
    "outputId": "1a2a344b-f582-447b-f286-d93e9391f1ab"
   },
   "outputs": [],
   "source": [
    "get_mel_sample(data, model, model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmtJbz24GAfL"
   },
   "source": [
    "##Еще"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eM19p222R7SE"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(train_loss_list, label='Train')\n",
    "# plt.plot(test_loss_list, label='Test')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(train_accuracy_list, label='Train')\n",
    "# plt.plot(test_accuracy_list, label='Test')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.title('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoW9l5_45pW0",
    "outputId": "9cf54ee9-978d-459a-d158-27c3f00b723e"
   },
   "outputs": [],
   "source": [
    "#источник\n",
    "#https://kubilaybozak.medium.com/record-audio-from-your-microphone-in-colab-colab-%C3%BCzerinden-mikrofon-ile-ses-kayd%C4%B1-alma-bfa56013624e\n",
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9cPzUPY5D7E"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To write this piece of code I took inspiration/code from a lot of places.\n",
    "It was late night, so I'm not sure how much I created or just copied o.O\n",
    "Here are some of the possible references:\n",
    "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
    "https://stackoverflow.com/a/18650249\n",
    "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
    "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
    "https://stackoverflow.com/a/49019356\n",
    "\"\"\"\n",
    "from IPython.display import HTML, Audio\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read as wav_read\n",
    "import io\n",
    "import ffmpeg\n",
    "\n",
    "AUDIO_HTML = \"\"\"\n",
    "<script>\n",
    "var my_div = document.createElement(\"DIV\");\n",
    "var my_p = document.createElement(\"P\");\n",
    "var my_btn = document.createElement(\"BUTTON\");\n",
    "var t = document.createTextNode(\"Press to start recording\");\n",
    "my_btn.appendChild(t);\n",
    "//my_p.appendChild(my_btn);\n",
    "my_div.appendChild(my_btn);\n",
    "document.body.appendChild(my_div);\n",
    "var base64data = 0;\n",
    "var reader;\n",
    "var recorder, gumStream;\n",
    "var recordButton = my_btn;\n",
    "var handleSuccess = function(stream) {\n",
    "  gumStream = stream;\n",
    "  var options = {\n",
    "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
    "    mimeType : 'audio/webm;codecs=opus'\n",
    "    //mimeType : 'audio/webm;codecs=pcm'\n",
    "  };            \n",
    "  //recorder = new MediaRecorder(stream, options);\n",
    "  recorder = new MediaRecorder(stream);\n",
    "  recorder.ondataavailable = function(e) {            \n",
    "    var url = URL.createObjectURL(e.data);\n",
    "    var preview = document.createElement('audio');\n",
    "    preview.controls = true;\n",
    "    preview.src = url;\n",
    "    document.body.appendChild(preview);\n",
    "    reader = new FileReader();\n",
    "    reader.readAsDataURL(e.data); \n",
    "    reader.onloadend = function() {\n",
    "      base64data = reader.result;\n",
    "      //console.log(\"Inside FileReader:\" + base64data);\n",
    "    }\n",
    "  };\n",
    "  recorder.start();\n",
    "  };\n",
    "recordButton.innerText = \"Recording... press to stop\";\n",
    "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
    "function toggleRecording() {\n",
    "  if (recorder && recorder.state == \"recording\") {\n",
    "      recorder.stop();\n",
    "      gumStream.getAudioTracks()[0].stop();\n",
    "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
    "  }\n",
    "}\n",
    "// https://stackoverflow.com/a/951057\n",
    "function sleep(ms) {\n",
    "  return new Promise(resolve => setTimeout(resolve, ms));\n",
    "}\n",
    "var data = new Promise(resolve=>{\n",
    "//recordButton.addEventListener(\"click\", toggleRecording);\n",
    "recordButton.onclick = ()=>{\n",
    "toggleRecording()\n",
    "sleep(2000).then(() => {\n",
    "  // wait 2000ms for the data to be available...\n",
    "  // ideally this should use something like await...\n",
    "  //console.log(\"Inside data:\" + base64data)\n",
    "  resolve(base64data.toString())\n",
    "});\n",
    "}\n",
    "});\n",
    "      \n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "def get_audio():\n",
    "  display(HTML(AUDIO_HTML))\n",
    "  data = eval_js(\"data\")\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  \n",
    "  process = (ffmpeg\n",
    "    .input('pipe:0')\n",
    "    .output('pipe:1', format='wav')\n",
    "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
    "  )\n",
    "  output, err = process.communicate(input=binary)\n",
    "  \n",
    "  riff_chunk_size = len(output) - 8\n",
    "  # Break up the chunk size into four bytes, held in b.\n",
    "  q = riff_chunk_size\n",
    "  b = []\n",
    "  for i in range(4):\n",
    "      q, r = divmod(q, 256)\n",
    "      b.append(r)\n",
    "\n",
    "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
    "  riff = output[:4] + bytes(b) + output[8:]\n",
    "\n",
    "  sr, audio = wav_read(io.BytesIO(riff))\n",
    "\n",
    "  return audio, sr"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "58KPDDULp8O8"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
